# File              : sup_train.yaml
# Author            : Zhepei Wang <zhepeiw2@illinois.edu>
# Date              : 27.01.2022
# Last Modified Date: 27.01.2022
# Last Modified By  : Zhepei Wang <zhepeiw2@illinois.edu>


seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]
np_rng: !new:numpy.random.RandomState [!ref <seed>]

resume_interrupt: False
resume_task_idx: 0

time_stamp: placeholder

# cont learning setup
# task_classes:
#   - !tuple (0, 1)
#   - !tuple (2, 3)
#   - !tuple (4, 5)
#   - !tuple (6, 7)
#   - !tuple (8, 9)
task_classes:
    - !tuple (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)
replay_num_keep: 0

use_mixup: False
mixup_alpha: 0.4
train_duration: 2.0

# Training parameters
number_of_epochs: 50
batch_size: 32
# lr: 0.001
# base_lr: 0.00000001
# max_lr: !ref <lr>
# step_size: 65000
warmup_epochs: 5
warmup_lr: !ref <batch_size> * 0 / 256
base_lr: !ref <batch_size> * 0.03 / 256
final_lr: !ref <batch_size> * 0.00000001 / 256

# dataset
sample_rate: 16000
data_folder: "/mnt/data/Sound Sets/UrbanSound8K/UrbanSound8K"
train_folds: [1, 2, 3, 4, 5, 6, 7, 8]
valid_folds: [9]
test_folds: [10]
label_encoder_path: "./dataset/label_encoder.txt"

train_dataloader_opts:
  batch_size: !ref <batch_size>
  num_workers: 8
  shuffle: True
  # drop_last: True

valid_dataloader_opts:
  batch_size: 32
  num_workers: 8


experiment_name: simsiam
# output_folder: !ref results/<experiment_name>/<seed>
output_folder: !ref /mnt/data/zhepei/outputs/cssl_sound/offline/<time_stamp>_seed_<seed>+<experiment_name>
train_log: !ref <output_folder>/train_log.txt
save_folder: !ref <output_folder>/save

# Experiment params
auto_mix_prec: True # Set it to True for mixed precision


# Feature parameters
n_mels: 80
left_frames: 0
right_frames: 0
deltas: False
amp_to_db: False
normalize: True
win_length: 25
hop_length: 10
n_fft: !ref <win_length> * <sample_rate> // 1000
f_min: 0
# Number of classes
n_classes: 10
emb_dim: 2048

# augmentation
# time_domain_aug: !new:speechbrain.lobes.augment.TimeDomainSpecAugment
#     sample_rate: !ref <sample_rate>
#     # drop_chunk_count_high: 2
#     # drop_chunk_noise_factor: 0.05
#     speeds: [90, 95, 100, 105, 110]
#     drop_freq_count_high: 4
#     drop_chunk_count_high: 3
#     # drop_chunk_length_low: 1000
#     # drop_chunk_length_high: 5000
spec_domain_aug: !new:augmentation.TFAugmentation
    time_warp: True
    time_warp_window: 8
    freq_mask: True
    freq_mask_width: !tuple (0, 10)
    n_freq_mask: 2
    time_mask: True
    time_mask_width: !tuple (0, 10)
    n_time_mask: 2
    replace_with_zero: True

# Functions
compute_features: !new:speechbrain.lobes.features.Fbank
    n_mels: !ref <n_mels>
    left_frames: !ref <left_frames>
    right_frames: !ref <right_frames>
    deltas: !ref <deltas>
    sample_rate: !ref <sample_rate>
    n_fft: !ref <n_fft>
    win_length: !ref <win_length>
    hop_length: !ref <hop_length>
    f_min: !ref <f_min>

mean_var_norm: !new:speechbrain.processing.features.InputNormalization
    norm_type: sentence
    std_norm: False

embedding_model: !new:models.tdnn.ECAPA_TDNN
    input_size: !ref <n_mels>
    channels: [1024, 1024, 1024, 1024, 3072]
    kernel_sizes: [5, 3, 3, 3, 1]
    dilations: [1, 2, 3, 4, 1]
    attention_channels: 128
    lin_neurons: !ref <emb_dim>
#     # channels: [512, 512, 512, 1024]
#     # kernel_sizes: [5, 3, 3, 1]
#     # dilations: [1, 2, 3, 1]
#     # attention_channels: 128
#     # lin_neurons: !ref <emb_dim>
# embedding_model: !new:models.pann.Cnn14
#     mel_bins: !ref <n_mels>
#     emb_dim: !ref <emb_dim>

projector: !new:models.modules.SimSiamProjector
    input_size: !ref <emb_dim>
    hidden_size: !ref <emb_dim>
    output_size: !ref <emb_dim>

predictor: !new:models.modules.SimSiamPredictor
    input_size: !ref <emb_dim>
    hidden_size: !ref <emb_dim> // 4

modules:
    compute_features: !ref <compute_features>
    embedding_model: !ref <embedding_model>
    # classifier: !ref <classifier>
    projector: !ref <projector>
    predictor: !ref <predictor>
    mean_var_norm: !ref <mean_var_norm>

compute_simsiam_cost: !new:torch.nn.CosineSimilarity
    dim: 2

acc_metric: !name:speechbrain.utils.Accuracy.AccuracyStats

# opt_class: !name:torch.optim.Adam
#     lr: !ref <base_lr>
#     weight_decay: 0.0005
#
# lr_scheduler_fn: !name:speechbrain.nnet.schedulers.CyclicLRScheduler
#     base_lr: !ref <final_lr>
#     max_lr: !ref <base_lr>
#     step_size: 888

opt_class: !name:torch.optim.SGD
    lr: !ref <base_lr>
    weight_decay: 0.0005
    momentum: 0.9

lr_scheduler_fn: !name:schedulers.SimSiamCosineScheduler
    warmup_epochs: !ref <warmup_epochs>
    warmup_lr: !ref <warmup_lr>
    num_epochs: !ref <number_of_epochs>
    base_lr: !ref <base_lr>
    final_lr: !ref <final_lr>
    steps_per_epoch: 222
    constant_predictor_lr: True

epoch_counter_fn: !name:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <number_of_epochs>

datapoint_counter: !new:utils.DatapointCounter
      
# # Logging + checkpoints
checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>

recoverables:
    embedding_model: !ref <embedding_model>
    # classifier: !ref <classifier>
    projector: !ref <projector>
    predictor: !ref <predictor>
    normalizer: !ref <mean_var_norm>
    datapoint_counter: !ref <datapoint_counter>

prev_checkpointer: null
# prev_checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
#     checkpoints_dir: !PLACEHOLDER

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_log>

# wandb
use_wandb: False
train_log_frequency: 20
wandb_logger_fn: !name:utils.MyWandBLogger
    initializer: !name:wandb.init
    entity: CAL
    project: cssl_sound
    name: !ref <time_stamp>+seed_<seed>+<experiment_name>
    dir: !ref <output_folder>
    reinit: True
    yaml_config: hparams/simsiam_train.yaml
    resume: False

