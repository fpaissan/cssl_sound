{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25645a33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T00:09:18.860853Z",
     "start_time": "2022-02-08T00:09:18.831398Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def sound( x, rate=8000, label=''):\n",
    "    from IPython.display import display, Audio, HTML\n",
    "    if label is '':\n",
    "        display( Audio( x, rate=rate))\n",
    "    else:\n",
    "        display( HTML( \n",
    "        '<style> table, th, td {border: 0px; }</style> <table><tr><td>' + label + \n",
    "        '</td><td>' + Audio( x, rate=rate)._repr_html_()[3:] + '</td></tr></table>'\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6015685d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T00:18:32.588329Z",
     "start_time": "2022-02-08T00:18:32.557834Z"
    }
   },
   "outputs": [],
   "source": [
    "from simsiam_train import dataio_prep\n",
    "import torch\n",
    "import speechbrain as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7a402",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T00:14:03.190525Z",
     "start_time": "2022-02-08T00:14:03.118956Z"
    }
   },
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'sample_rate': 16000,\n",
    "}\n",
    "label_encoder_path = './dataset/label_encoder.txt'\n",
    "label_encoder = sb.dataio.encoder.CategoricalEncoder()\n",
    "label_encoder.load_or_create(label_encoder_path)\n",
    "\n",
    "csv_path = '/mnt/data/zhepei/outputs/cssl_sound/results/2022-02-05+06-01-38_seed_1234+offline/save/train_task0_replay.csv'\n",
    "ds = dataio_prep(\n",
    "    hparams,\n",
    "    csv_path,\n",
    "    label_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a7867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T04:00:23.072435Z",
     "start_time": "2022-02-08T04:00:23.040035Z"
    }
   },
   "outputs": [],
   "source": [
    "from speechbrain.lobes import augment\n",
    "time_domain_aug = augment.TimeDomainSpecAugment(\n",
    "    sample_rate=hparams['sample_rate'],\n",
    "    speeds=[95, 100, 105],\n",
    "    drop_freq_count_high=4,\n",
    "    drop_chunk_count_high=3,\n",
    "    drop_chunk_length_low=1000,\n",
    "    drop_chunk_length_high=8000,\n",
    "    drop_chunk_noise_factor=0.,\n",
    "#     drop_chunk_count_high=2,\n",
    "#     drop_chunk_noise_factor=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de5579",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T03:56:55.713542Z",
     "start_time": "2022-02-08T03:56:55.680566Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_aug(wavs):\n",
    "    lens = torch.ones(wavs.shape[0]).to(wavs.device)\n",
    "    wavs_aug = time_domain_aug(wavs, lens)\n",
    "    if wavs_aug.shape[1] > wavs.shape[1]:\n",
    "        wavs_aug = wavs_aug[:, 0 : wavs.shape[1]]\n",
    "    else:\n",
    "        zero_sig = torch.zeros_like(wavs)\n",
    "        zero_sig[:, 0 : wavs_aug.shape[1]] = wavs_aug\n",
    "        wavs_aug = zero_sig\n",
    "    return wavs_aug\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e549b64d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T04:00:46.632944Z",
     "start_time": "2022-02-08T04:00:46.585952Z"
    }
   },
   "outputs": [],
   "source": [
    "x = ds[1211]['sig'].unsqueeze(0)\n",
    "x1 = compute_aug(x)\n",
    "x2 = compute_aug(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33714a5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T04:00:46.824141Z",
     "start_time": "2022-02-08T04:00:46.781528Z"
    }
   },
   "outputs": [],
   "source": [
    "sound(x[0].numpy(), 16000, label='orig')\n",
    "sound(x1[0].numpy(), 16000, label='x1')\n",
    "sound(x2[0].numpy(), 16000, label='x2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798fe86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch110",
   "language": "python",
   "name": "pytorch110"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
